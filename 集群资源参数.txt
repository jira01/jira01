    建表时指定{
		STORED AS orc
		tblproperties ('orc.compress'='SNAPPY','creator'='作者','created_at'='2021-07-30 14:00:00（创建时间）');
	}
	
	set hive.exec.reducers.max=500;								控制最大的reducer的数量
    set mapreduce.job.reduces=200;								默认启动的reduce数						
    set mapred.reduce.tasks=500;								设置Reduce数量
    set mapred.map.tasks=500;									设置map数量
	
    set mapred.output.compress=true;							下面有答案
	
    set hive.exec.compress.output=true;							下面有答案
	
    set hive.exec.dynamic.partition.mode=nonstrict;				动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，
																nonstrict模式表示允许所有的分区字段都可以使用动态分区。
																一般需要设置为nonstrict
																
    set hive.exec.dynamic.partition=true;						是否开启动态分区功能，默认false关闭。
																使用动态分区时候，该参数必须设置成true
																
    set hive.exec.max.dynamic.partitions=100000;				在所有执行MR的节点上，最大一共可以创建多少个动态分区。
    set hive.exec.max.dynamic.partitions.pernode=100000;		在每个执行MR的节点上，最大可以创建多少个动态分区。
	
    set hive.auto.convert.join = true;							下面有答案
	
    set mapreduce.job.split.metainfo.maxsize=-1;				忽略文件数量校验
    set yarn.app.mapreduce.am.command-opts=-Xmx3072m;			MRAppMaster需要的堆内存大小
    set yarn.app.mapreduce.am.resource.mb=4096;					MR运行于YARN上时，为AM分配多少内存
    set hive.map.aggr=true;										下面有答案
	
    set hive.groupby.skewindata=true;							数据倾斜优化map输出随机相同key分配到Reduce中第二个 MapReduce 
																任务再根据预处理的数据结果按照Group By Key分布到reduce中(聚合)
																
    set hive.exec.parallel=true;								下面有答案
    set hive.exec.parallel.thread.number=16;					下面有答案
	
    set hive.merge.sparkfiles = true;							是否在hive on spark任务后开启小文件合并
    set spark.sql.hive.mergeFiles=true;							开启sparksql小文件合并	
    set spark.driver.extraJavaOptions=-XX:+UseG1GC;				垃圾回收机制设置
    set spark.executor.extraJavaOptions=-XX:+UseG1GC;			垃圾回收机制设置
    set spark.sql.autoBroadcastJoinThreshold=-1					设置为-1，广播被禁用
	
	set hive.default.fileformat=orc; 							设置文件格式
	set mapred.output.compress = true;							MR输出压缩
	set hive.exec.compress.output = true;						作业最终的输出 map/reduce 输出压缩（一般采用序列化文件存储）
	set hive.exec.compress.intermediate=true;					开启hive作业mapreduce任务中间压缩功能
	set hive.intermediate.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;（常用）
	set hive.merge.mapfiles = true; 							在只有map的作业结束时合并小文件，
	set hive.merge.mapredfiles = true;							在Map-Reduce的任务结束时合并小文件，默认为False；
	set hive.merge.size.per.task = 256000000;					合并后每个文件的大小，默认256000000
	set hive.merge.smallfiles.avgsize = 128000000;				如果原先输出的文件平均大小小于这个值，则开启小文件合并。
																比如输出原本有100个文件，总大小1G，那平均每个文件大小只有10M，
																如果我们这个参数设置为16M，这时就会开启文件合并
	
	set mapred.min.split.size = 128000000;						每个map最小的split输入大小的参数
	set mapred.min.split.size.per.node = 128000000;				每个节点处理的最小split
	set mapred.min.split.size.per.rack = 128000000;				每个机架处理的最小split
	set hive.input.format = org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;   输入格式
	set hive.exec.reducers.bytes.per.reducer = 128000000;		每个reducer的大小，
	
	set hive.auto.convert.join = true ;							MapJoin开启
	set hive.mapjoin.smalltable.filesize = 1024000000;--1GB		小于这个阈值放入内存中进行mapjion
	
	set hive.exec.parallel=true;								控制是否可以并行
	set hive.exec.parallel.thread.number=8; 同一个sql来说同时可以运行的job的最大值,该参数默认为8.此时最大可以同时运行8个job.
	
	set hive.map.aggr=true;										提高HiveQL聚合的执行性能
	set hive.new.job.grouping.set.cardinality = 64;				此值决定Hive是否添加额外的job